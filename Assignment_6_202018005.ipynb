{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_6_202018005.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7eALSMejDoXo",
        "2ZfDxiusEL-b"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ehbug_kQ4RW"
      },
      "source": [
        "import glob"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmFRYmnDTMEp"
      },
      "source": [
        "%%capture\n",
        "!gdown https://drive.google.com/uc?id=1JuawXQmYVkjpfL3H0blqjDrqw8V1lHrC\n",
        "!unrar e /content/FIRE_Dataset_EN_2010.rar\n",
        "!gunzip /content/en.qrels.76-125.2010.txt.gz\n",
        "!tar -xzvf English-Data.tgz"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbv6sG-TSdVm"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chRV-JGEY3sN"
      },
      "source": [
        "e = open(\"/content/en.qrels.76-125.2010.txt\")\n",
        "q = open(\"/content/en.topics.76-125.2010.txt\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BOqi6Dsw6E6"
      },
      "source": [
        "estr = e.read()\n",
        "qstr = q.read()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQa4UCrryXmL"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cngl6IKLwxHt"
      },
      "source": [
        "\n",
        "elist = estr.split(\"\\n\")\n",
        "# elist = [est for est in es if est.endswith('1')]\n",
        "\n",
        "edir = {}\n",
        "for e in elist[:-1]:\n",
        "  a, b, c, d = e.split()\n",
        "  if a not in edir:\n",
        "    edir[a] = [(c, d)]\n",
        "  else:\n",
        "    edir[a].append((c, d))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-CZamwDxINK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a3018c-977f-40d6-e511-f729d189b4f2"
      },
      "source": [
        "import re\n",
        "ls = qstr.split('</top>')[:-1]\n",
        "Queries={}\n",
        "for query in ls:\n",
        "  soup = BeautifulSoup(query, 'lxml')\n",
        "  n = soup.find('num').text\n",
        "  s = soup.find('desc').text\n",
        "  s += soup.find('title').text\n",
        "  # s = soup.find('narr').text\n",
        "  \n",
        "  Queries[n] = s\n",
        "Queries"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'100': '\\nMonica Bedi charged with obtaining forged passports at\\nHyderabad.\\nMonica Bedi and the passport forgery case',\n",
              " '101': \"\\nDetails of the drink-and-drugs party at the late Pramod\\nMahajan's official bungalow in which Rahul (his son), Bibek\\nMoitra, and possibly others were involved.\\nDrug party at Pramod Mahajan's bungalow\",\n",
              " '102': '\\nCharges of doping against Shoaib Akhtar and Mohammad Asif.\\nPakistani cricketers involved in a doping scandal',\n",
              " '103': \"\\nWhat is India's position on the Indo-Pak conflict over the\\nBaglihar hydro-electric power project?\\nBilateral problems surrounding the Baglihar hydro-electric\\npower project\",\n",
              " '104': '\\nWhat legal steps has Jaya Bachchan taken on being\\ndisqualified from Rajya Sabha membership for holding an\\noffice of profit?\\nJaya Bachchan sacked from Rajya Sabha membership',\n",
              " '105': '\\nCBI investigations into the alleged involvement of the Chief\\nMinister and highly placed bureaucrats of Uttar Pradesh in\\nthe multi-crore Taj heritage corridor scandal.\\nTaj heritage corridor scandal',\n",
              " '106': '\\nTaslima Nasreen\\'s novel \"Shame\" banned for hurting Muslim\\nreligious sentiments.\\nBan on Taslima Nasreen\\'s novel \"Shame\"',\n",
              " '107': '\\nAccusations against the BJP of publishing a CD containing\\nanti-Muslim material during the run-up to the election in\\nUttar Pradesh, India, and steps taken by the BJP in this\\nregard.\\nFurore over the release of a CD containing\\nanti-Muslim sentiments in Uttar Pradesh',\n",
              " '108': '\\nDemand for a Greater Nagaland made by NSCN, a Naga\\norganization, and protests made by neighbouring states\\nagainst this demand. \\nGreater Nagaland',\n",
              " '109': \"\\nRaj Thackeray's decision to form a new political party in\\nMumbai, and his announcement about the new party.\\nNew political party formed by Raj Thackeray\",\n",
              " '110': '\\nBorder trade through Nathu La and its impact on\\nSino-Indian relations.\\nSino-Indian relations and border trade',\n",
              " '111': \"\\nBan on Mumbai's dance bars and protests by dancers against\\nthe ban.\\nDance bars banned in Mumbai\",\n",
              " '112': '\\nLinks between the Goa and Manikchand Gutkha manufacturing\\ncompanies and Dawood Ibrahim.\\nLinks between Gutkha manufacturers and the underworld',\n",
              " '113': '\\nClashes within the BNP and between the BNP and the Awami\\nLeague in Bangladesh.\\nPolitical clashes in Bangladesh',\n",
              " '114': '\\nArms deal signed by George Fernandez with Denel, and demands\\nmade by Pranab Mukherjee for an investigation into\\nirregularities in this deal.\\nInvestigation of the arms scandal in the Defence Ministry',\n",
              " '115': '\\nCasualties resulting from the serial blasts in the Sankatmochan\\ntemple.\\nSerial blasts in Varanasi',\n",
              " '116': '\\nWhat steps did the ACB take against Daya Nayak in the\\ndisproportionate assets (DA) case?\\nEncounter specialist Daya Nayak',\n",
              " '117': \"\\nThe offer for talks made by the tribals and the Orissa\\ngovernment's plea for central mediation in connection with\\nthe controversy over land acquisition at Kalinganagar.\\nControversy over land at Kalinganagar\",\n",
              " '118': '\\nPossible involvement of Pakistani terrorist groups behind\\nthe Ayodhya attack, and the effect of the attack.\\nTerrorist strike at Ayodhya',\n",
              " '119': '\\nControversy about Taj Mahal take over.\\nTaj Mahal controversy',\n",
              " '120': '\\nCharges against Anara Gupta, erstwhile Miss Jammu, for her\\ninvolvement in the sex CD scandal, and reports from the\\nAndhra Pradesh forensic laboratory in this regard.\\nSex CD scandal involving Anara Gupta',\n",
              " '121': '\\nDeadly explosions on the Samjhauta Express.\\nBlasts on Samjhauta Express',\n",
              " '122': \"\\nSurrender of Sanjay Dutt, the actor, convicted in the 1993\\nMumbai blasts case.\\nSanjay Dutt's surrender\",\n",
              " '123': '\\nDeath of Palestinian leader Yasser Arafat.\\nDeath of Yasser Arafat',\n",
              " '124': '\\nTrade in illegal drugs in various states of India.\\nSale of illegal drugs in various Indian states',\n",
              " '125': '\\nSiege of the Lal Masjid in Islamabad by fundamentalist students.\\nAttack on the Lal Masjid',\n",
              " '76': '\\nReasons behind the protests by Meena leaders against the\\ninclusion of Gurjars in the Scheduled Tribes.\\nClashes between the Gurjars and Meenas',\n",
              " '77': '\\nAttacks by Hezbollah guerrillas on Indian and Israeli forces.\\nAttacks by Hezbollah guerrillas',\n",
              " '78': '\\nConflict between Ashok Singhal, the president of Vishwa\\nHindu Parishad, and L.K. Advani, the BJP leader over the Ram\\nMandir issue.\\nConflict between Advani and Singhal over the Ram\\nMandir issue',\n",
              " '79': '\\nPlans to build a road from China to Mount Everest.\\nBuilding roads between China and Mount Everest',\n",
              " '80': '\\nInitiation of legal proceedings against Advani for his\\ninvolvement in the demolition of Babri Masjid.\\nBabri Masjid demolition case started against Advani',\n",
              " '81': '\\nThe Health Ministry in India has made certain plans to\\nprotect Indian children against the outbreak of Japanese\\nEncephalitis. What problems have arisen in the course of\\nimplementing these plans?\\nProblems related to the immunization programme\\nagainst Japanese Encephalitis in India',\n",
              " '82': '\\nThe proposed bus service between Srinagar and Muzaffarabad,\\nand its role in solving the Indo-Pak dispute.\\nProposed bus service between Srinagar and Muzaffarabad',\n",
              " '83': '\\nAttempts made by Laloo Prasad Yadav and Ram Vilas Paswan to\\ngain the votes of Muslim voters.\\nElection campaign of Laloo Prasad Yadav and Ram Vilas\\nPaswan',\n",
              " '84': \"\\nAllegations raised by Brinda Karat that medicines sold by\\nSwami Ramdev contain animal parts.\\nBrinda Karat's allegations against Swami Ramdev\",\n",
              " '85': '\\nOrder passed by the court to remand Abu Salem, accused in\\nthe Mumbai Bomb Blast case, in jail custody.\\nAbu Salem, accused in the Mumbai Bomb Blast case, in\\njail custody',\n",
              " '86': \"\\nThe Government's decision to privatize the Mumbai and Delhi\\nairports and its call for tender bids in this regard.\\nPrivatization of the Mumbai and Delhi airports\",\n",
              " '87': '\\nDiscussions between Manmohan Singh, Prime Minister of India,\\nand Pervez Musharraf, President of Pakistan, regarding the\\nposition of troops around Siachen.\\nDiscussions between Manmohan Singh and Pervez Musharraf regarding\\nthe position of troops around Siachen',\n",
              " '88': \"\\nArrests of Jayendra Saraswati, Shankaracharya of Kanchi and\\nVijayendra Saraswati, for their alleged involvement in\\nthe murder of Shankar Raman, and people's protests against\\nthese arrests. \\nPopular protests against the arrest of the accused in the Shankar\\nRaman murder case\",\n",
              " '89': '\\nAlleged involvement of the External Affairs Minister Natwar\\nSingh and other Congress ministers in the Iraqi oil-for-food\\nscam, and related investigations.\\nInvolvement of Congress ministers in the oil-for-food scam',\n",
              " '90': '\\nA visit by a team of Indian representatives to Dhaka to\\ndiscuss issues like sharing of water, security, and training\\ncamps for militants.\\nIndian representatives visit Bangladesh',\n",
              " '91': '\\nCharges of financial corruption against Pratibha Patil.\\nAllegations of financial corruption against Pratibha Patil',\n",
              " '92': '\\nInsurgent activities of the Tamil Tigers of Sri Lanka.\\nActivities of the Tamil Tigers of Sri Lanka',\n",
              " '93': '\\nMembers of the Indian parliament caught on camera, accepting\\nbribes for raising questions in Parliament.\\nTaking bribes for raising questions in parliament',\n",
              " '94': '\\nInvestigations into the accusations that classified\\ninformation has been leaked by the Indian Navy.\\nIndian Navy accused of leaking classified information',\n",
              " '95': '\\nThe racism row on the Big Brother show involving Shilpa\\nShetty and Jade Goody.\\nRacism row on the Big Brother show',\n",
              " '96': \"\\nStatements made by Pramod Mahajan's killer in court, denying\\ncharges against him.\\nPramod Mahajan's killer\",\n",
              " '97': '\\nFeud between Mukesh Ambani and Anil Ambani regarding ownership of the\\nReliance Group.\\nQuarrel between the Ambani brothers regarding ownership of the\\nReliance Group',\n",
              " '98': \"\\nIndia's dismissal of China's claims on Arunachal Pradesh.\\nIndia dismisses China's claims on Arunachal Pradesh\",\n",
              " '99': \"\\nEvidence regarding Laloo Prasad Yadav's involvement in the\\nfodder scam.\\nLaloo Prasad Yadav and the fodder scam\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPmsfV_7pBw-"
      },
      "source": [
        "def getdocFiles():\n",
        "  files = {}\n",
        "  for file in glob.iglob(\"TELEGRAPH_UTF8/**/*.utf8\", recursive=True):\n",
        "    files[file.split('/')[-1]] = open(file)\n",
        "  return files"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_7YqN1wpRwK"
      },
      "source": [
        "files = getdocFiles()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw8bUaGHWOIJ"
      },
      "source": [
        "class doc:\n",
        "  def __init__(self, docid, docobj):\n",
        "    \"\"\"\n",
        "    docobj should be IOTextwrapper\n",
        "    \"\"\"\n",
        "    self.docid = docid\n",
        "    self.docobj = docobj\n",
        "\n",
        "  def read(self):\n",
        "    return self.docobj.read()\n",
        "\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwsumjgGZGOx"
      },
      "source": [
        "docs = [doc(id, obj) for id, obj in files.items()]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EKGbiG2K4vr"
      },
      "source": [
        "class corpus:\n",
        "  def __iter__(self, docs):\n",
        "    for doc in docs:\n",
        "      yield doc.read()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XdksRSIdt7Z"
      },
      "source": [
        "def count():\n",
        "  i = 0 \n",
        "  while True:\n",
        "    yield i\n",
        "    i+=1\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WhcvMi4faNP"
      },
      "source": [
        "corps = corpus()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tAUHy2_OaEv"
      },
      "source": [
        "class RochioAlgorithm:\n",
        "  \"\"\"\n",
        "  Custom Implementation of rochio algorithm\n",
        "\n",
        "  Parameters: \n",
        "  alpha, beta, gamma\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, Queries, KnownRel, docs):\n",
        "    \"\"\"\n",
        "    Queries : dictonary containing ids and queries in format {id:Query}\n",
        "    KnownRel : dictonary containing ids docid relevance score(0 or 1) in format\n",
        "\n",
        "      {id: [\n",
        "        (docid, relevancescore), ...\n",
        "      ]\n",
        "      ...}\n",
        "    docs : list of doc objects\n",
        "\n",
        "    \"\"\"\n",
        "    self.Queries = Queries\n",
        "    self.KnownRel = KnownRel\n",
        "    self.OpQueries = {}\n",
        "    self.docs = docs\n",
        "\n",
        "  def iter(self):\n",
        "    \"\"\"\n",
        "    iterator to yield docs and queries one by one\n",
        "    \"\"\"\n",
        "    for doc in self.docs:\n",
        "      yield doc.read()\n",
        "    for queryid in self.Queries:\n",
        "      yield self.Queries[queryid]\n",
        "  \n",
        "\n",
        "  def nRelDocs(self, queryid):\n",
        "    \"\"\"\n",
        "    Returns number of relevant docs for a query with queryid\n",
        "    \"\"\"\n",
        "    return sum([b == '1' for a, b in self.KnownRel[queryid]])\n",
        "  \n",
        "\n",
        "  def nIrrDocs(self, queryid):\n",
        "    \"\"\"\n",
        "    Returns number of Irrelevant docs for a query with queryid\n",
        "    \"\"\"\n",
        "    return sum([b=='0' for a, b in self.KnownRel[queryid]])\n",
        "\n",
        "  def vectorizer(self, fn):\n",
        "    \"\"\"\n",
        "    tfidf vectorizer calculates tfidf vectors for docs and queries\n",
        "    \"\"\"\n",
        "    itr = self.iter()\n",
        "    termdocMat = fn(self.docs, token_pattern='[a-zA-Z]+', stop_words={'english'}).fit_transform(itr)\n",
        "    self.tfidfvec = {}\n",
        "    \n",
        "    for i in range(len(self.docs)):\n",
        "      self.tfidfvec[self.docs[i].docid] = termdocMat[i, :]\n",
        "    \n",
        "    c = count()\n",
        "    self.tfidfq = {}\n",
        "    for queryid in self.Queries:\n",
        "      self.tfidfq[queryid] = termdocMat[len(self.docs) + next(c), :]\n",
        "    del termdocMat\n",
        "\n",
        "  def word2vecVectorizer(self, fn, files):\n",
        "    \"\"\"\n",
        "    word2vec vectorizer calculates word2vec representation(sums w2vec vectors for each word) for docs and queries\n",
        "    \"\"\"\n",
        "\n",
        "    from gensim.test.utils import datapath\n",
        "    from gensim import utils\n",
        "    from gensim.parsing.preprocessing import preprocess_string, preprocess_documents\n",
        "\n",
        "    class MyCorpus:\n",
        "      \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
        "\n",
        "      def __iter__(self):\n",
        "        for file in files:\n",
        "          yield preprocess_string(files[file].read())\n",
        "\n",
        "    sentences = MyCorpus()\n",
        "\n",
        "    import gensim.models\n",
        "\n",
        "    skipmodel = gensim.models.Word2Vec(sentences=sentences, sg=1, size=300, window=5, workers=2)\n",
        "    \n",
        "    docs = {file:preprocess_string(files[file]) for file in files}\n",
        "\n",
        "    queries = {query:preprocess_string(self.Queries[query]) for query in self.Queries}\n",
        "\n",
        "    words=[]\n",
        "    for wrds in docs.values():\n",
        "      words.extend(wrds)\n",
        "    wordSet = set(words)\n",
        "    self.docsV = {doc:sum([skipmodel.wv[word] for word in docs[doc] if word in wordSet and word in model.wv]) for doc in docs}\n",
        "    self.w2vQueries = {query:sum([model.wv[word] for word in queries[id] if word in wordSet and word in model.wv]) for query in queries}\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def sumRelIrrDocs(self, docsV, queryID, rel):\n",
        "    \"\"\"\n",
        "    returns the sum of docs tfidfvec\n",
        "    rel : 0 for irrelevant docs 1 for relevant docs\n",
        "    \"\"\"\n",
        "    flag = 0\n",
        "    for docid, relscore in self.KnownRel[queryID]:\n",
        "      if relscore == rel:\n",
        "        if flag == 0:\n",
        "          summ = docsV[docid]\n",
        "          flag = 1\n",
        "        else:\n",
        "          summ += docsV[docid]\n",
        "    return summ\n",
        "\n",
        "  def computeOpQuery(self, docsV, queriesV,queryid, alpha, beta, gamma):\n",
        "    \"\"\"\n",
        "    Computes optimized query vector representation for vector representation of query with queryid \n",
        "    \"\"\"\n",
        "    return alpha * queriesV[queryid] + beta * self.sumRelIrrDocs(docsV, queryid, \n",
        "          '1')/self.nRelDocs(queryid) - gamma * self.sumRelIrrDocs(docsV, queryid, '0')/self.nIrrDocs(queryid)\n",
        "    \n",
        "\n",
        "  def getOptimizedQueries(self, docsV, queriesV, alpha, beta, gamma):\n",
        "    \"\"\"\n",
        "    computes optimized queries for all queries\n",
        "    \"\"\"\n",
        "    for queryid in self.Queries:\n",
        "      self.OpQueries[queryid] = self.computeOpQuery(docsV, queriesV ,queryid, alpha, beta, gamma)\n",
        "    \n",
        "  \n",
        "  \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x47siJ3d2zYY"
      },
      "source": [
        "def count():\n",
        "  \"\"\"\n",
        "  simple counter\n",
        "  \"\"\"\n",
        "  i = 0 \n",
        "  while True:\n",
        "    yield i\n",
        "    i+=1\n",
        "c= count()\n",
        "\n",
        "# fileIndexer for docs\n",
        "fileIndexer = {file:next(c) for file in files}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16v2ZTiO1oiC"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def cosineSim(a, b):\n",
        "  \"\"\"\n",
        "  returns cosine similarity between two sparse vectors\n",
        "  \"\"\"\n",
        "  return cosine_similarity(a, b)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOPtPazN1B3Z"
      },
      "source": [
        "class Retrieval:\n",
        "  \"\"\"\n",
        "  Custom Implementation for performing retrieval task\n",
        "  \"\"\"\n",
        "  def __init__(self, rochiobj, docV):\n",
        "    self.OpQueries = rochiobj.OpQueries\n",
        "    self.docRep = docV\n",
        "    self.fileIndexer = fileIndexer\n",
        "    self.KnownQRel = {query:[] for query in rochiobj.KnownRel}\n",
        "    for query in rochiobj.KnownRel:\n",
        "      for lst in rochiobj.KnownRel[query]:\n",
        "        if lst[-1] == '1':\n",
        "          self.KnownQRel[query].append(lst)\n",
        "    \n",
        "  \n",
        "  def Similarity(self, simFunc):\n",
        "    \"\"\"\n",
        "    calculates similarity between all possible pairs of docs and queries using similarity function passed\n",
        "    \"\"\"\n",
        "    self.docmeas = {}\n",
        "    for query in self.OpQueries:\n",
        "      print(next(c1), end=',')\n",
        "      ls = []\n",
        "      for doc in self.docRep:\n",
        "        ls.append((query, doc, simFunc(self.docRep[doc], self.OpQueries[query])))\n",
        "      self.docmeas[query] = ls  \n",
        "\n",
        "  def Retrieve(self):\n",
        "    \"\"\"\n",
        "    sorts the docs in decreasing order of similarity score and chops off undesired one's\n",
        "    \"\"\"\n",
        "    #Sorting in decreasing order of similarity score\n",
        "    for query in self.docmeas:\n",
        "      self.docmeas[query].sort(key=lambda x: x[2][0][0], reverse=True)\n",
        "    \n",
        "    for query in self.OpQueries:\n",
        "      self.docmeas[query] = self.docmeas[query][:10]\n",
        "    \n",
        "  def getMap(self):\n",
        "    \"\"\"\n",
        "    returns the map score\n",
        "    \"\"\"\n",
        "    # self.Similarity(cosineSim)\n",
        "    self.Retrieve()\n",
        "    docmeas1 = {}\n",
        "    for query in self.OpQueries:\n",
        "      docmeas1[query] = [(c[1], 1 if isin(c[1], self.KnownQRel[query]) else 0) for c in self.docmeas[query]]\n",
        "    queryap = {}\n",
        "    for query in self.OpQueries:\n",
        "      # print(query)\n",
        "      gtp = len(self.KnownQRel[query])\n",
        "      p = 0\n",
        "      i = 0\n",
        "      for j in range(len(docmeas1[query])):\n",
        "        # print(docmeas1[query][j][1])\n",
        "        if docmeas1[query][j][1] == 1:\n",
        "    \n",
        "          i += 1\n",
        "          p += i/(j+1)\n",
        "      if i == 0:\n",
        "        queryap[query] = 0\n",
        "      else:\n",
        "        queryap[query] = p/i\n",
        "    return sum(queryap.values())/ len(queryap)\n",
        "  \n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eALSMejDoXo"
      },
      "source": [
        "# TFIDF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od8BuMdiTNQ7"
      },
      "source": [
        "r = RochioAlgorithm(Queries, edir, docs)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORGtLd2ldYWp"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1InypREXUOIj"
      },
      "source": [
        "r.vectorizer(TfidfVectorizer)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71RprFeMhuX9"
      },
      "source": [
        "r.getOptimizedQueries(1, 0.75, 0.15)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhoTnhaVONu6"
      },
      "source": [
        "c1 = count() "
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xty9s6Ne9LU"
      },
      "source": [
        "def isin(el, obj):\n",
        "  for x in obj:\n",
        "    if x[0] == el:\n",
        "      return True\n",
        "  return False"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWWNdT0sCMf1"
      },
      "source": [
        "ret = Retrieval(r, r.tfidfvec)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMsk1mi-oXJC"
      },
      "source": [
        "ret.docmeas = obj"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJa7HALeGSFs",
        "outputId": "1feee3d4-0b4f-4221-a9e8-07e03ed3f80b"
      },
      "source": [
        "ret.getMap()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7463174358802956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGcpjMT7olhS"
      },
      "source": [
        "Copied similarity scores to obj to use it later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AvQqoGrDpbv"
      },
      "source": [
        "# obj = ret.docmeas.copy()"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZfDxiusEL-b"
      },
      "source": [
        "# word2vec\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq6XWTNXETeC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az4lxOoVvq1h"
      },
      "source": [
        "files = getdocFiles()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKz4oldVsbNB"
      },
      "source": [
        "r.word2vecVectorizer(files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oebf0RcqNQ_-"
      },
      "source": [
        "r.getOptimizedQueries(r.docsV, r.w2vQueries, 1, 0.75, 0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "henPwMsITeYo"
      },
      "source": [
        "def count():\n",
        "  i = 0 \n",
        "  while True:\n",
        "    yield i\n",
        "    i+=1\n",
        "c= count()\n",
        "fileIndexer = {file:next(c) for file in files}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f1L1AaqR_Dd"
      },
      "source": [
        "retw2v = Retrieval(r, r.docsV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCCn9mHuVN3P"
      },
      "source": [
        "def cosineSim1(a, b):\n",
        "  an = np.linalg.norm(a)\n",
        "  bn = np.linalg.norm(b)\n",
        "  if an == 0 or bn == 0:\n",
        "    return 0\n",
        "\n",
        "  return np.dot(a, b)/(an*bn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odwvTLbIThCU"
      },
      "source": [
        "retw2v.Similarity(cosineSim1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxN3Pu2wV0HG",
        "outputId": "606cf409-fb33-4e09-f284-96bd953fcc8d"
      },
      "source": [
        "retw2v.getMap()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6743543764247651"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qvkbHUCb-wa"
      },
      "source": [
        "# Adding synonyms using wordnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGAU84qacDil",
        "outputId": "141a2922-f9b5-4d75-e23c-137829dedeea"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def addSynonymns(words):\n",
        "  new_words = []\n",
        "  for word in words:\n",
        "    for syn in wordnet.synsets(word):\n",
        "      for l in syn.lemmas():\n",
        "        if l.name() not in new_words:\n",
        "          new_words.append(l.name())\n",
        "        \n",
        "  return new_words"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub0-ILyaeXZF"
      },
      "source": [
        "QWithSyns = {query:\" \".join(addSynonymns(Queries[query].split())) for query in Queries} "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kswPUE7eyy7f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRyLf6oMgAjU"
      },
      "source": [
        "r = RochioAlgorithm(QWithSyns, edir, docs)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDplGKE0zI-i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bfKnXxLgv3t"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0ue9pMWgxXX"
      },
      "source": [
        "r.vectorizer(TfidfVectorizer)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm1HYyS4g6bH"
      },
      "source": [
        "r.getOptimizedQueries(r.tfidfvec, r.tfidfq, 1, 0.75, 0.15)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q4T4hZFhBIF"
      },
      "source": [
        "c1 = count() "
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJAkiPDXhBIG"
      },
      "source": [
        "def isin(el, obj):\n",
        "  for x in obj:\n",
        "    if x[0] == el:\n",
        "      return True\n",
        "  return False"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlBigfHQhBIH"
      },
      "source": [
        "ret = Retrieval(r, r.tfidfvec)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxm0Kqsqi2Hv"
      },
      "source": [
        "ret.Similarity(cosineSim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWOTzwqJhBIK",
        "outputId": "2f8cd2e8-45f7-44d2-f918-b66484a34841"
      },
      "source": [
        "ret.getMap()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6574325674258753"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GetJPR8cjVIY"
      },
      "source": [
        "# Word2Vec\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq2hUt7Sjc1I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3vR1ZU5jtjq"
      },
      "source": [
        "files = getdocFiles()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_JnxCG_jtjt"
      },
      "source": [
        "r.word2vecVectorizer(files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbhrHSXWjtju"
      },
      "source": [
        "r.getOptimizedQueries(r.docsV, r.w2vQueries, 1, 0.75, 0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL0B-TOwjtju"
      },
      "source": [
        "def count():\n",
        "  i = 0 \n",
        "  while True:\n",
        "    yield i\n",
        "    i+=1\n",
        "c= count()\n",
        "fileIndexer = {file:next(c) for file in files}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLBtenn0jtjw"
      },
      "source": [
        "retw2v = Retrieval(r, r.docsV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-GeQLZijtjx"
      },
      "source": [
        "def cosineSim1(a, b):\n",
        "  an = np.linalg.norm(a)\n",
        "  bn = np.linalg.norm(b)\n",
        "  if an == 0 or bn == 0:\n",
        "    return 0\n",
        "\n",
        "  return np.dot(a, b)/(an*bn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVG1kVeQjtjx"
      },
      "source": [
        "retw2v.Similarity(cosineSim1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KKBGx8Kjtjy",
        "outputId": "16f6d229-f5f0-4cce-dc0f-0f0d022242af"
      },
      "source": [
        "retw2v.getMap()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5467523645983254"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp2DJHErY_el"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}